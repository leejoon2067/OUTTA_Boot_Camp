{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38406d21",
   "metadata": {},
   "source": [
    "### 데이터 불러오기\n",
    "\n",
    "파일의 이름에 숫자만 다른 것을 이용하여 반복문으로 한번에 데이터를 가져와 df에 할당합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c80cdc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4219063710.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    echo\"# OUTTA_Boot_Camp\" >> README.md\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "echo \"# OUTTA_Boot_Camp\" >> README.md\n",
    "git init\n",
    "git add README.md\n",
    "git commit -m \"first commit\"\n",
    "git branch -M main\n",
    "git remote add origin https://github.com/leejoon2067/OUTTA_Boot_Camp.git\n",
    "git push -u origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c0059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import re\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "#일반적으로 사용하는 데이터 파일 불러오는 방법\n",
    "df= pd.read_excel(\"raw_data.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61520f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#반복문을 이용해서 데이터 파일 data에 저장\n",
    "\n",
    "#data=[]\n",
    "#for i in range(1,6):\n",
    "    #data.함수1(pd.read_excel(f\"파일명규칙활용.xlsx\"))    \n",
    "#    data.add(pd.read_excel(f\"C:/Users/leejo/Downloads/outta 부트캠프/제공데이터/제공데이터/rank1.xlsx\")\n",
    "    \n",
    "#함수2를 이용하여 data에 있는 데이터들을 합치기\n",
    "#df = pd.함수2(data, ignore_index=True)   \n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66df6d17",
   "metadata": {},
   "source": [
    "### 결측값 제거\n",
    "\n",
    "크롤링 코드 작성 시 크롤링하지 못한 정보는 '없음'으로 저장하게 했기 때문에 '없음'의 갯수로 결측값의 갯수를 파악합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f82995",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############제공된 코드 건드리지 마세요 ###################\n",
    "\n",
    "### 데이터 컬럼별 없음(결측치) 개수 파악\n",
    "\n",
    "col_name= df.columns    #컬럼명 저장\n",
    "from collections import Counter\n",
    "\n",
    "for i in col_name:\n",
    "    print(i,Counter(df[i])[\"없음\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec5090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#피부정보, 별점, 피부타입, 피부고민, 자극도 중 하나라도 값이 '없음'인 경우 \n",
    "df_new = df[(df['피부정보'] == '없음') | (df['별점'] == '없음')| (df['피부타입'] == '없음')| (df['자극도'] == '없음')]\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6147bbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 별점, 피부타입, 피부고민, 자극도 값이 없음은 제거한 데이터를 df2에 저장\n",
    "\n",
    "df2= df[~df.index.isin(df_new.index)]\n",
    "df2.reset_index(drop=True, inplace=True)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aabf144",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############제공된 코드 건드리지 마세요 ###################\n",
    "### 데이터 컬럼별 없음(결측치) 개수 파악\n",
    "\n",
    "col_name= df2.columns    #컬럼명 저장\n",
    "from collections import Counter\n",
    "\n",
    "for i in col_name:\n",
    "    print(i,Counter(df2[i])[\"없음\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f4a48f",
   "metadata": {},
   "source": [
    "### 정가, 할인가 데이터 타입 변경\n",
    "\n",
    "정가,할인가의 쉼표를 제거하고 데이터 타입을 int64로 바꿔줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080f3c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2['정가'] = df2['정가'].str.replace(',', '').astype('int64')\n",
    "# df2['할인가'] = df2['할인가'].str.replace(',' , '').astype('int64')\n",
    "\n",
    "# df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66844f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b276ece",
   "metadata": {},
   "source": [
    "### 아이디 컬럼 삭제\n",
    "\n",
    "모델 학습 시 아이디 정보는 필요하지 않기 때문에 제거해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d863642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(columns = ['아이디'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb864889",
   "metadata": {},
   "source": [
    "### 별점에서 숫자만 남기기\n",
    "\n",
    "현재 별점은 5점만점에 X점과 같은 형식으로 되어있습니다. 여기서 X만 남기고 데이터 타입을 int64로 바꿔줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61ca93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['별점'] = df2['별점'].apply(lambda x: int(re.findall(r'\\d+',x)[1]))\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af923f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd05bfa2",
   "metadata": {},
   "source": [
    "### 피부정보 컬럼을 여러컬럼으로 구분\n",
    "\n",
    "피부정보에는 최대 피부타입, 피부톤, 2개의 피부고민 총 4개로 이루어져 있습니다.  \n",
    "해당 텍스트는 공백으로 구분되어있고 이를 이용해 4개의 컬럼(user피부타입/user피부톤/user피부고민1/user피부고민2)으로 만들어 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130518af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#힌트: split 함수\n",
    "df2[[\"user피부타입\", \"user피부톤\", \"user피부고민1\", \"user피부고민2\"]] = df2[\"피부정보\"].str.split(expand=True)\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ad259f",
   "metadata": {},
   "source": [
    "#### user피부타입 컬럼에서 복합성/건성/지성/민감성/트러블성/약건성/중성 을 제외하고 모두 np.NaN 처리 해줍니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e6a2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user피부타입에서 해당하지 않는 값은 nan 처리\n",
    "\n",
    "types = ['복합성', '건성', '지성', '민감성', '트러블성', '약건성', '중성']\n",
    "def to_nan(x):\n",
    "    if x not in types:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return x\n",
    "        \n",
    "        \n",
    "df2[\"user피부타입\"] = df2['user피부타입'].apply(to_nan)\n",
    "df2[\"user피부타입\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548bd591",
   "metadata": {},
   "source": [
    "#### user피부고민2의 결측값을 user피부톤 컬럼값으로 채운 후  (웜톤/쿨톤/여름쿨톤/봄웜톤/가을웜톤/겨울쿨톤) 값을  np.NaN 처리 해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e951298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_skin_tone(row):\n",
    "    if pd.isna(row['user피부고민2']):\n",
    "        return row['user피부톤']\n",
    "    else:\n",
    "        return row['user피부고민2']\n",
    "\n",
    "\n",
    "df2[\"user피부고민2\"]= df2.apply(fill_skin_tone, axis =1)\n",
    "df2[\"user피부고민2\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1ad969",
   "metadata": {},
   "outputs": [],
   "source": [
    "tones = ['웜톤', '쿨톤', '여름쿨톤', '봄웜톤', '가을웜톤', '겨울쿨톤']\n",
    "\n",
    "def to_nan_피부고민2(x):\n",
    "    if x in tones:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return x\n",
    "        \n",
    "        \n",
    "df2[\"user피부톤\"] = df2['user피부톤'].apply(to_nan_피부고민2)\n",
    "df2[\"user피부고민2\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee1ceba",
   "metadata": {},
   "source": [
    "### user피부타입, usesr피부고민1, user피부고민2 에서 결측값 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b6f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a6618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dropna(subset = ['user피부타입', 'user피부고민1', 'user피부고민2'], inplace = True)\n",
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e727a527",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5189bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39aec36",
   "metadata": {},
   "source": [
    "### df2를 df3에 복사한 후 상품명컬럼의 값을 간단하게 변경해줍니다.\n",
    "* 대용량 한정기획] 구달 청귤 비타C 잡티케어 세럼 50ml+31ml 증정 기획                                     : goodal\n",
    "* [1등 국민미스트] 달바 화이트 트러플 퍼스트 스프레이 세럼 100ml + 100ml 기획세트                        : dalba_mist\n",
    "* 성분에디터 그린토마토 포어 리프팅 앰플 플러스 30ml+10ml 기획                                           : sungboon\n",
    "* [2세대 천만크림] 닥터지 레드 블레미쉬 클리어 수딩 크림 70ml+30ml 세트                                  : dr_g\n",
    "* 라로슈포제 NEW 시카플라스트 밤B5+ 100ml 기획(+시카토너 50ml 증정)                                      : larocheposay\n",
    "* [100ml+100ml/단독기획] 토리든 다이브인 저분자 히알루론산 수딩크림 더블기획                             : torriden_cream\n",
    "* 에스트라 아토베리어365 크림 80ml 기획 (+하이드로에센스 25ml+무기자차선크림10ml 증정)(2305)             : aestura_cream\n",
    "* 에스트라 아토베리어365 로션 150ml 기획 (+하이드로에센스 25ml+무기자차선크림10ml 증정)                  : aestura_lotion\n",
    "* [단독기획] 토리든 다이브인 저분자 히알루론산 세럼 더블기획 (50ml+50ml)                                 : torriden_serum\n",
    "* [5월 올영픽/대용량] 파티온 노스카나인 트러블 세럼 단독 기획(50ml+15ml)                                 : fation\n",
    "* [쿵야 키링&스티커 증정] V&A 안티옥시던트 래디언스 앰플 더블 기획 (30ml+30ml)                           : V&A\n",
    "* [박은빈 PICK] 한율 어린쑥 수분진정크림 55ml 기획(+45ml 리필 증정)                                      : hanyul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2b8b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df2.copy()\n",
    "\n",
    "\n",
    "#상품명 간소화\n",
    "def name_min(x):\n",
    "    if \"[홍현희 PICK/ 한정기획] 구달 청귤 비타C 잡티케어 세럼 50ml+50ml 리필기획\" in x:\n",
    "        return \"goodal_serum\"\n",
    "    elif \"[8월 올영픽/1+1단독] 성분에디터 그린토마토 포어 리프팅 앰플 플러스 30ml 더블 기획\" in x:\n",
    "        return \"green_tomato_ampule\"\n",
    "    elif \"[뽐니PICK/한정기획] 토리든 다이브인 세럼 50ml 리필 한정 기획(+50ml 리필팩+수딩 크림 20ml)\" in x:\n",
    "        return \"torriden_serum\"\n",
    "    elif \"[8월 올영픽/소의튜브 PICK] 에스네이처 아쿠아 스쿠알란 수분크림 60ml 기획 (60ml+30ml)\" in x:\n",
    "        return \"snature_cream\"\n",
    "    elif \"[8월 올영픽/리필기획] 아누아 어성초 77 수딩 토너 350ml 리필 기획세트(350ml+350ml리필)\" in x:\n",
    "        return \"anua_toner\"\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "# 결과 출력\n",
    "df3[\"상품명\"]= df3[\"상품명\"].apply(name_min)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fef46f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77892340",
   "metadata": {},
   "source": [
    "### 브랜드, 피부정보, user피부톤 컬럼을 삭제합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d719dc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.drop(columns = ['브랜드'])\n",
    "df3 = df3.drop(columns =['피부정보'])\n",
    "df3 = df3.drop(columns = ['user피부톤'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328ef12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c02132",
   "metadata": {},
   "source": [
    "### 컬럼명을 변경해줍니다.\n",
    "* 피부타입 -> 효과1  \n",
    "* 피부고민 -> 효과2  \n",
    "* user피부타입 -> 피부타입  \n",
    "* user피부고민1 -> 피부고민1  \n",
    "* user피부고민2 -> 피부고민2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3abb73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.rename(columns = {\n",
    "    \"피부타입\": \"효과1\",\n",
    "    \"피부고민\": \"효과2\",\n",
    "    \"user피부타입\": \"피부타입\",\n",
    "    \"user피부고민1\": \"피부고민1\",\n",
    "    \"user피부고민2\": \"피부고민2\"\n",
    "}, inplace = True)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cee98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ca7a56",
   "metadata": {},
   "source": [
    "## 데이터 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3566a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[\"자극도\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d5ad3d",
   "metadata": {},
   "source": [
    "### 직접 함수를 만들어 자극도 컬럼을 레이블인코딩 합니다.\n",
    "* 자극없이 순해요 -> 0\n",
    "* 보통이에요 -> 1\n",
    "* 자극이 느껴져요 -> 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b8cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def 자극도인코딩(x):\n",
    "    if x == \"자극없이 순해요\":\n",
    "        return 0\n",
    "    elif x == \"보통이에요\":\n",
    "        return 1\n",
    "    elif x == \"자극이 느껴져요\":\n",
    "        return 2\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "\n",
    "df3[\"자극도\"]= df3[\"자극도\"].apply(자극도인코딩)\n",
    "df3[\"자극도\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2e465c",
   "metadata": {},
   "source": [
    "### 상품명, 카테고리, 효과1, 효과2, 피부타입, 피부고민1, 피부고민2 은  get_dummies를 이용해 원핫인코딩을 합니다.\n",
    "결과를 df4에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca177fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4= pd.get_dummies(df3, columns = ['상품명', '카테고리', '효과1', '효과2', '피부타입', '피부고민1', '피부고민2']).astype(int)\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccbd6e3",
   "metadata": {},
   "source": [
    "# 랜덤포레스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c770ec2",
   "metadata": {},
   "source": [
    "#### 피처값과 타겟값을 지정해줍니다. (target : 별점, 피처는 별점 제외 모든 컬럼)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703244f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features= df4.drop(columns = ['별점'])\n",
    "target= df4['별점']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0ee21e",
   "metadata": {},
   "source": [
    "#### 저장한 피처와 타겟을 가지고 train : test 데이터를 8:2로 나누어 줍니다. random_state = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7f9d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebe350f",
   "metadata": {},
   "source": [
    "#### df4의 별점의 분포를 막대그래프로 시각화하여 불균형한지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368cbb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#한글 깨짐 방지\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "\n",
    "#막대그래프 코드 작성\n",
    "count_star = df4['별점'].value_counts().sort_index()\n",
    "plt.bar(count_star.index, count_star.values)\n",
    "plt.xlabel(\"별점\")\n",
    "plt.ylabel(\"갯수\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b36a2ba",
   "metadata": {},
   "source": [
    "### 불균형한 데이터 샘플링 SMOTE 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d7826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불균형 데이터 오버샘플링 SMOTE \n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_over, y_train_over = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"SMOTE 적용 전 train 데이터셋 shape : \", X_train.shape, y_train.shape)\n",
    "print('SMOTE 적용 후 train 데이터셋 shape :', X_train_over.shape, y_train_over.shape)\n",
    "print('SMOTE 적용 후 train 타겟 별점 분포',y_train_over.value_counts() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de42b99e",
   "metadata": {},
   "source": [
    "### 데이터 스케일링\n",
    "피처의 단위를 동일하게 만들기 위해 StandardScaler로 스케일링을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d025c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "                      \n",
    "X_train_scaled = ss.fit_transform(X_train_over) \n",
    "X_test_scaled = ss.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8504f15d",
   "metadata": {},
   "source": [
    "### 그리드서치로 최적의 파라미터 찾기 \n",
    "1. 지정할 파라미터와 값을 params에 저장합니다.  \n",
    "2. 랜덤포레스트 모델을 생성하고 rfc로 할당합니다. (random_state=100, n_jobs=-1)  \n",
    "3. 그리드서치를 실행하여 grid_cv로 할당합니다. (cv=3, n_jobs=-1)\n",
    "4. 스케일링 완료한 훈련 데이터를 grid_cv에 fit해줍니다.\n",
    "5. 최적의 파라미터를 print 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6104be63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#각 파라미터 값 넣기\n",
    "params = { 'n_estimators' : [50, 100, 150],\n",
    "           'max_depth' : [None, 10, 20],\n",
    "           'max_features': ['auto', 'sqrt', 'log2'],\n",
    "           'min_samples_split' : [2, 10, 20]\n",
    "            }\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(random_state = 100, n_jobs = -1)\n",
    "grid_cv = GridSearchCV(rfc, param_grid = params, cv = 3, n_jobs = -1)     # cv는 교차 검증을 위해 분할되는 학습 데이터의 세트 수\n",
    "grid_cv.fit(X_train_scaled, y_train_over)\n",
    "\n",
    "print(f'최적 파라미터: {grid_cv.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76236670",
   "metadata": {},
   "source": [
    "### 랜덤포레스트 모델 훈련\n",
    "위에서 구한 최적 파라미터를 활용하여 랜덤포레스트 모델을 만들고 해당 모델로 다시 훈련시킵니다. random_state=100, n_jobs=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f0d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "best_param = {\n",
    "    'max_depth' : 20,\n",
    "    'max_features' : 'log2',\n",
    "    'min_samples_split' : 2,\n",
    "    'n_estimators' : 150\n",
    "}\n",
    "rfc= RandomForestClassifier(random_state=100, n_jobs=-1, **best_param)\n",
    "rfc.fit(X_train_scaled, y_train_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3219092",
   "metadata": {},
   "source": [
    " ### 모델 평가지표 결과값이 한번에 나오도록 함수 만들기\n",
    " 함수에 y_test와 pred를 입력하면 정확도, 정밀도, 재현율, f1스코어가 데이터 프레임으로 나오도록 함수를 만듭니다.  \n",
    " 단, 정확도, 정밀도, 재현율, f1스코어의 average는 모두 'micro'로 설정  \n",
    " 딕셔너리를 활용하여 데이터 프레임을 만들어주세요.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab7e5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score\n",
    "\n",
    "def _metrics(y_test, pred):\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred, average='micro')\n",
    "    recall = recall_score(y_test, pred, average='micro')\n",
    "    f1 = f1_score(y_test, pred, average='micro')\n",
    "    \n",
    "    dict_metrics = {\n",
    "        'Accuracy': [acc],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F1 Score': [f1]\n",
    "    }\n",
    "    df_metrics = pd.DataFrame(dict_metrics)\n",
    "\n",
    "    return df_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fa4def",
   "metadata": {},
   "source": [
    "#### 스케일링한 test데이터를 가지고 모델에 적용하여 나온 예측값을 pred에 할당하고 평가지표함수로 성능을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dbc01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rfc.predict(X_test_scaled)\n",
    "\n",
    "_metrics(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38ba83c",
   "metadata": {},
   "source": [
    "### 피처 중요도 확인하기\n",
    "\n",
    "피처 중요도 값을 저장한 feat_importance 값을 내림차순하여 20개만 top_20에 할당합니다.  \n",
    "그 값을 가지고 barplot을 만들어 줍니다. \n",
    "* 제목 : 피처 중요도 Top2 20 \n",
    "* figsize = (8,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6734d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#제공 코드\n",
    "feat_importance = pd.Series(rfc.feature_importances_, index=features.columns)\n",
    "\n",
    "top20 = feat_importance.sort_values(ascending = False)[:20]\n",
    "\n",
    "#한글 깨짐 방지\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('피처 중요도 Top2 20')\n",
    "sns.barplot(x=top20.values, y=top20.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25111d93",
   "metadata": {},
   "source": [
    "### 혼동행렬\n",
    "y_test와 예측값 pred를 이용하여 혼동행렬 생성하여 cf에 할당합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e04884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf = confusion_matrix(y_test, pred)\n",
    "cf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f03d755",
   "metadata": {},
   "source": [
    "### 혼동행렬 시각화\n",
    "cf를 데이터 프레임(cf_matrix)으로 만든 후 컬럼명과, 인덱스를 1~5점으로 저장합니다.   \n",
    "데이터 프레임을 heatmap으로 만들어 줍니다. ( anno=True  -> 각 셀에 숫자 입력 , fmt='d'  -> 정수형으로 나오도록함)   \n",
    "x라벨 : 예측값, y라벨 : 실제값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551e4e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix= pd.DataFrame(cf, index=range(1, 6), columns = range(1, 6))\n",
    "\n",
    "#히트맵 코드 작성\n",
    "plt.title('혼동행렬')\n",
    "sns.heatmap(cf_matrix, annot = True, fmt = 'd', cmap = 'Blues', cbar = False)\n",
    "plt.xlabel(\"예측값\")\n",
    "plt.ylabel(\"실제값\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9513816c",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc4282e",
   "metadata": {},
   "source": [
    "### 랜덤포레스트와 데이터 스케일링까지 과정이 반복됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808ba1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 다시 확인해보기\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac5d49f",
   "metadata": {},
   "source": [
    "#### 피처값과 타겟값  (target : 별점, 피처는 별점 제외 모든 컬럼)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123560de",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=df4.drop('별점', axis = 1)\n",
    "target= df4[\"별점\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36febf3e",
   "metadata": {},
   "source": [
    "#### 저장한 피처와 타겟을 가지고 train : test 데이터를 8:2로 나누어 줍니다. random_state = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01188865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#train/test 데이터 분리 8:2로\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79526ee8",
   "metadata": {},
   "source": [
    "#### 불균형 데이터 smote로 오버샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0df86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_over, y_train_over = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40293bb4",
   "metadata": {},
   "source": [
    "#### 피처의 단위를 동일하게 만들기 위해 StandardScaler로 스케일링을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d963e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "      \n",
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train_over)\n",
    "X_test_scaled = ss.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d33f09",
   "metadata": {},
   "source": [
    "### 그리드서치로 최적의 파라미터 찾기 \n",
    "1. 지정할 파라미터와 값을 knn_params에 저장합니다.  \n",
    "2. KNN 모델을 생성하고 knn으로 할당합니다. (n_jobs=-1)  \n",
    "3. 그리드서치를 실행하여 grid_cv로 할당합니다. (cv=5, n_jobs=-1)\n",
    "4. 스케일링 완료한 훈련 데이터를 grid_cv에 fit해줍니다.\n",
    "5. 최적의 파라미터를 print 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a0c7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#각 파라미터 값 넣기\n",
    "knn_params = {\n",
    "    'n_neighbors' : [3, 5, 7],\n",
    "    'weights' : ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "\n",
    "knn= KNeighborsClassifier(n_jobs = -1)\n",
    "\n",
    "grid_cv=GridSearchCV(knn, knn_params, cv = 5 , n_jobs = -1)       \n",
    "grid_cv.fit(X_train_scaled,y_train_over)\n",
    "\n",
    "\n",
    "print(f'최적 하이퍼 파라미터: {grid_cv.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bd42eb",
   "metadata": {},
   "source": [
    "### KNN 모델 훈련\n",
    "위에서 구한 최적 파라미터를 활용하여 knn 모델을 만들고 해당 모델로 다시 훈련시킵니다. n_jobs=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce46b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(n_jobs=-1, n_neighbors=3, weights='uniform')\n",
    "knn.fit(X_train_scaled,y_train_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0e6e0d",
   "metadata": {},
   "source": [
    "#### 스케일링한 test데이터를 가지고 모델에 적용하여 나온 예측값을 knn_pred에 할당하고 평가지표함수로 성능을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb42321",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred= knn.predict(X_test_scaled)\n",
    "\n",
    "_metrics(y_test,knn_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67a849a",
   "metadata": {},
   "source": [
    "### 혼동행렬\n",
    "y_test와 예측값 knn_pred를 이용하여 혼동행렬 생성하여 knn_cf에 할당합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548383b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "knn_cf = confusion_matrix(y_test, knn_pred)\n",
    "knn_cf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e72e1bc",
   "metadata": {},
   "source": [
    "### 혼동행렬 시각화\n",
    "knn_cf를 데이터 프레임(knn_cf_matrix)으로 만든 후 컬럼명과, 인덱스를 1~5점으로 저장합니다.   \n",
    "데이터 프레임을 heatmap으로 만들어 줍니다. ( anno=True  -> 각 셀에 숫자 입력 , fmt='d'  -> 정수형으로 나오도록함)   \n",
    "x라벨 : 예측값, y라벨 : 실제값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d970da56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "knn_cf_matrix= pd.DataFrame(knn_cf, index = range(1, 6), columns = range(1, 6))\n",
    "\n",
    "#히트맵 코드 작성\n",
    "sns.heatmap(knn_cf_matrix, annot = True, fmt = 'd', cmap = 'reds', cbar = False)\n",
    "plt.title(\"KNN 혼동행렬\")\n",
    "plt.xlabel(\"예측값\")\n",
    "plt.ylabel(\"실제값\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1c34c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deb5759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
